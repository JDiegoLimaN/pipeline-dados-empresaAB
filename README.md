ğŸ“Š Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos
Projeto desenvolvido durante o curso "Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos".
Este repositÃ³rio contÃ©m um exemplo prÃ¡tico de um pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) implementado em Python utilizando orientaÃ§Ã£o a objetos. 

ğŸ“˜ Sobre o Projeto
O objetivo deste projeto Ã© unir dados provenientes de duas fontes distintas:

Empresa A: dados no formato JSON
Empresa B: dados no formato CSV
ApÃ³s a leitura dos arquivos, os dados sÃ£o transformados (renomeando colunas e unindo as bases), e por fim salvos em um Ãºnico arquivo CSV como parte do processo de carga (Load).

ğŸ§± Estrutura do Projeto

pipeline-dados-empresaAB/
â”œâ”€â”€ data_raw/                     # Dados brutos das empresas
â”‚   â”œâ”€â”€ dados_empresaA.json       # Dados da empresa A (JSON)
â”‚   â””â”€â”€ dados_empresaB.csv        # Dados da empresa B (CSV)
â”‚
â”œâ”€â”€ data_processed/               # Dados processados apÃ³s o pipeline
â”‚   â””â”€â”€ dados_combinados.csv      # Arquivo final combinado
â”‚
â”œâ”€â”€ processamento_dados.py        # Classe principal 'Dados' para manipulaÃ§Ã£o dos dados
â”œâ”€â”€ fusao_mercados_fev.py         # Script principal que executa o pipeline ETL
â”‚
â””â”€â”€ README.md                     # Este arquivo

profile
Qwen3-235B-A22B
9:38 am
Claro! Vou te ajudar a montar um README.md completo e bem estruturado para o seu repositÃ³rio. Este arquivo serÃ¡ essencial para que outras pessoas entendam, usem e contribuam com o seu projeto.

Aqui estÃ¡ uma sugestÃ£o de conteÃºdo para o README.md, baseada nos scripts e no curso:

ğŸ“Š Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos
Projeto desenvolvido durante o curso "Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos".
Este repositÃ³rio contÃ©m um exemplo prÃ¡tico de um pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) implementado em Python utilizando orientaÃ§Ã£o a objetos. 

ğŸ“˜ Sobre o Projeto
O objetivo deste projeto Ã© unir dados provenientes de duas fontes distintas:

Empresa A: dados no formato JSON
Empresa B: dados no formato CSV
ApÃ³s a leitura dos arquivos, os dados sÃ£o transformados (renomeando colunas e unindo as bases), e por fim salvos em um Ãºnico arquivo CSV como parte do processo de carga (Load).

ğŸ§± Estrutura do Projeto
pipeline-dados-empresaAB/
â”œâ”€â”€ data_raw/                     # Dados brutos das empresas
â”‚   â”œâ”€â”€ dados_empresaA.json       # Dados da empresa A (JSON)
â”‚   â””â”€â”€ dados_empresaB.csv        # Dados da empresa B (CSV)
â”‚
â”œâ”€â”€ data_processed/               # Dados processados apÃ³s o pipeline
â”‚   â””â”€â”€ dados_combinados.csv      # Arquivo final combinado
â”‚
â”œâ”€â”€ processamento_dados.py        # Classe principal 'Dados' para manipulaÃ§Ã£o dos dados
â”œâ”€â”€ fusao_mercados_fev.py         # Script principal que executa o pipeline ETL
â”‚
â””â”€â”€ README.md                     # Este arquivo
âš™ï¸ Funcionalidades
Leitura automÃ¡tica de dados em formatos JSON ou CSV.
Renomeio flexÃ­vel de colunas com mapeamento customizÃ¡vel.
JunÃ§Ã£o de mÃºltiplas fontes de dados.
Salvamento em arquivo CSV organizado.
ImplementaÃ§Ã£o orientada a objetos para fÃ¡cil manutenÃ§Ã£o e escalabilidade.
ğŸ› ï¸ Como Executar
1. Requisitos
Certifique-se de ter instalado:

Python 3.x
Ambiente virtual (recomendado)
Pacotes necessÃ¡rios: json, csv
2. Clonando o repositÃ³rio

git clone https://github.com/seu-usuario/pipeline-dados-empresaAB.git 
cd pipeline-dados-empresaAB

3. Criando ambiente virtual (opcional mas recomendado)

python -m venv venv
source venv/bin/activate    # Linux/Mac
# ou
venv\Scripts\activate       # Windows

profile
Qwen3-235B-A22B
9:38 am
Claro! Vou te ajudar a montar um README.md completo e bem estruturado para o seu repositÃ³rio. Este arquivo serÃ¡ essencial para que outras pessoas entendam, usem e contribuam com o seu projeto.

Aqui estÃ¡ uma sugestÃ£o de conteÃºdo para o README.md, baseada nos scripts e no curso:

ğŸ“Š Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos
Projeto desenvolvido durante o curso "Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos".
Este repositÃ³rio contÃ©m um exemplo prÃ¡tico de um pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) implementado em Python utilizando orientaÃ§Ã£o a objetos. 

ğŸ“˜ Sobre o Projeto
O objetivo deste projeto Ã© unir dados provenientes de duas fontes distintas:

Empresa A: dados no formato JSON
Empresa B: dados no formato CSV
ApÃ³s a leitura dos arquivos, os dados sÃ£o transformados (renomeando colunas e unindo as bases), e por fim salvos em um Ãºnico arquivo CSV como parte do processo de carga (Load).

ğŸ§± Estrutura do Projeto
pipeline-dados-empresaAB/
â”œâ”€â”€ data_raw/                     # Dados brutos das empresas
â”‚   â”œâ”€â”€ dados_empresaA.json       # Dados da empresa A (JSON)
â”‚   â””â”€â”€ dados_empresaB.csv        # Dados da empresa B (CSV)
â”‚
â”œâ”€â”€ data_processed/               # Dados processados apÃ³s o pipeline
â”‚   â””â”€â”€ dados_combinados.csv      # Arquivo final combinado
â”‚
â”œâ”€â”€ processamento_dados.py        # Classe principal 'Dados' para manipulaÃ§Ã£o dos dados
â”œâ”€â”€ fusao_mercados_fev.py         # Script principal que executa o pipeline ETL
â”‚
â””â”€â”€ README.md                     # Este arquivo
âš™ï¸ Funcionalidades
Leitura automÃ¡tica de dados em formatos JSON ou CSV.
Renomeio flexÃ­vel de colunas com mapeamento customizÃ¡vel.
JunÃ§Ã£o de mÃºltiplas fontes de dados.
Salvamento em arquivo CSV organizado.
ImplementaÃ§Ã£o orientada a objetos para fÃ¡cil manutenÃ§Ã£o e escalabilidade.
ğŸ› ï¸ Como Executar
1. Requisitos
Certifique-se de ter instalado:

Python 3.x
Ambiente virtual (recomendado)
Pacotes necessÃ¡rios: json, csv
2. Clonando o repositÃ³rio
bash
git clone https://github.com/seu-usuario/pipeline-dados-empresaAB.git 
cd pipeline-dados-empresaAB
3. Criando ambiente virtual (opcional mas recomendado)
bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
# ou
venv\Scripts\activate       # Windows
4. Instalando dependÃªncias (nenhuma externa necessÃ¡ria neste projeto)
Este projeto utiliza apenas bibliotecas nativas do Python (json e csv), entÃ£o nÃ£o hÃ¡ necessidade de instalar pacotes adicionais. 

5. Baixando os dados (exemplo com wget)
Se ainda nÃ£o tiver os arquivos, vocÃª pode baixÃ¡-los com:

mkdir -p data_raw

wget -O data_raw/dados_empresaA.json https://cdn3.gnarususercontent.com.br/3062-pipeline-dados/dados/dados_empresaB.csv 
wget -O data_raw/dados_empresaB.csv https://cdn3.gnarususercontent.com.br/3062-pipeline-dados/dados/dados_empresaA.json 

âš ï¸ AtenÃ§Ã£o: Confira se os links estÃ£o corretos e disponÃ­veis.

6. Executando o pipeline

python fusao_mercados_fev.py

ApÃ³s a execuÃ§Ã£o, o arquivo dados_combinados.csv serÃ¡ criado na pasta data_processed.

ğŸ“ Exemplo de SaÃ­da
SerÃ¡ exibido no terminal:

['Nome do Produto', 'Categoria do Produto', 'PreÃ§o do Produto (R$)', ...]
Quantidade de linhas: X
...
Arquivo salvo em: data_processed/dados_combinados.csv

['Nome do Produto', 'Categoria do Produto', 'PreÃ§o do Produto (R$)', ...]
Quantidade de linhas: X
...
Arquivo salvo em: data_processed/dados_combinados.csv

profile
Qwen3-235B-A22B
9:38 am
Claro! Vou te ajudar a montar um README.md completo e bem estruturado para o seu repositÃ³rio. Este arquivo serÃ¡ essencial para que outras pessoas entendam, usem e contribuam com o seu projeto.

Aqui estÃ¡ uma sugestÃ£o de conteÃºdo para o README.md, baseada nos scripts e no curso:

ğŸ“Š Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos
Projeto desenvolvido durante o curso "Pipeline de Dados: Combinando Python e OrientaÃ§Ã£o a Objetos".
Este repositÃ³rio contÃ©m um exemplo prÃ¡tico de um pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) implementado em Python utilizando orientaÃ§Ã£o a objetos. 

ğŸ“˜ Sobre o Projeto
O objetivo deste projeto Ã© unir dados provenientes de duas fontes distintas:

Empresa A: dados no formato JSON
Empresa B: dados no formato CSV
ApÃ³s a leitura dos arquivos, os dados sÃ£o transformados (renomeando colunas e unindo as bases), e por fim salvos em um Ãºnico arquivo CSV como parte do processo de carga (Load).

ğŸ§± Estrutura do Projeto
pipeline-dados-empresaAB/
â”œâ”€â”€ data_raw/                     # Dados brutos das empresas
â”‚   â”œâ”€â”€ dados_empresaA.json       # Dados da empresa A (JSON)
â”‚   â””â”€â”€ dados_empresaB.csv        # Dados da empresa B (CSV)
â”‚
â”œâ”€â”€ data_processed/               # Dados processados apÃ³s o pipeline
â”‚   â””â”€â”€ dados_combinados.csv      # Arquivo final combinado
â”‚
â”œâ”€â”€ processamento_dados.py        # Classe principal 'Dados' para manipulaÃ§Ã£o dos dados
â”œâ”€â”€ fusao_mercados_fev.py         # Script principal que executa o pipeline ETL
â”‚
â””â”€â”€ README.md                     # Este arquivo
âš™ï¸ Funcionalidades
Leitura automÃ¡tica de dados em formatos JSON ou CSV.
Renomeio flexÃ­vel de colunas com mapeamento customizÃ¡vel.
JunÃ§Ã£o de mÃºltiplas fontes de dados.
Salvamento em arquivo CSV organizado.
ImplementaÃ§Ã£o orientada a objetos para fÃ¡cil manutenÃ§Ã£o e escalabilidade.
ğŸ› ï¸ Como Executar
1. Requisitos
Certifique-se de ter instalado:

Python 3.x
Ambiente virtual (recomendado)
Pacotes necessÃ¡rios: json, csv

2. Clonando o repositÃ³rio
bash
git clone https://github.com/seu-usuario/pipeline-dados-empresaAB.git 
cd pipeline-dados-empresaAB
3. Criando ambiente virtual (opcional mas recomendado)
bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
# ou
venv\Scripts\activate       # Windows
4. Instalando dependÃªncias (nenhuma externa necessÃ¡ria neste projeto)
Este projeto utiliza apenas bibliotecas nativas do Python (json e csv), entÃ£o nÃ£o hÃ¡ necessidade de instalar pacotes adicionais. 

5. Baixando os dados (exemplo com wget)
Se ainda nÃ£o tiver os arquivos, vocÃª pode baixÃ¡-los com:

bash
mkdir -p data_raw

wget -O data_raw/dados_empresaA.json https://cdn3.gnarususercontent.com.br/3062-pipeline-dados/dados/dados_empresaB.csv 
wget -O data_raw/dados_empresaB.csv https://cdn3.gnarususercontent.com.br/3062-pipeline-dados/dados/dados_empresaA.json 
âš ï¸ AtenÃ§Ã£o: Confira se os links estÃ£o corretos e disponÃ­veis.

6. Executando o pipeline
bash
python fusao_mercados_fev.py
ApÃ³s a execuÃ§Ã£o, o arquivo dados_combinados.csv serÃ¡ criado na pasta data_processed.

ğŸ“ Exemplo de SaÃ­da
SerÃ¡ exibido no terminal:

['Nome do Produto', 'Categoria do Produto', 'PreÃ§o do Produto (R$)', ...]
Quantidade de linhas: X
...
Arquivo salvo em: data_processed/dados_combinados.csv
ğŸ“Œ O que foi aprendido?
Como organizar um projeto de engenharia de dados;
ManipulaÃ§Ã£o de dados em JSON e CSV;
Uso de classes e orientaÃ§Ã£o a objetos para modularizaÃ§Ã£o;
CriaÃ§Ã£o de um pipeline ETL simples e eficiente;
PrÃ¡ticas de refatoraÃ§Ã£o e encapsulamento.

ğŸ’¬ Contato
Se quiser compartilhar feedbacks, melhorias ou dÃºvidas:

DiÃªgo Lima
www.linkedin.com/in/nascimento-jdl
